# mlops_LisinFedor


# kuber

1. Разверните Kubernetes. Поднял через minikube, `kubectl cluster-info` скрин в папке артифактов. (+5 баллов)
2. Стандартный pod: `online-inference-pod.yaml`. Добавил `configMapKeyRef` и `secretKeyRef` (+4 балла)
3. Пропишите Requests / Limits и напишите, зачем это нужно в описании PR. Закоммитьте файл `online-inference-pod-resources.yaml` (+2 балла)
    - Limits устанавливает ограничение на максимальное потребление
    - Requests устанавливает ограничение на минимальное, т.е. сколько вообще надо бы попросить у кубера, чтоб под запустился.
    - А ещё эти параметры условно обязательны, потому что без них **kubernetes extension** для **vscode** подчеркивает весь yaml и пишет варнинги, такие дела.

4. Добавил запуск сервера с задержкой + запуск в отдельном процессе с таймаутом 60 секунд. Тут докеры https://hub.docker.com/repository/docker/theolisin/mlops_kube  (+ 3 балла)

А дальше мне стало в этот раз лень( Если на какой-нибудь работе попадутся остальные задачи, доделаю :D


# airflow_ml_dags

В этом ДЗ я использовал те же самые данные по сердечным заболеваниям, что и в первых двух.

## Dags

### new_data_imitation.py
Даг, который имитирует поступление новыйх данных на s3. Ежедневно он берёт оригинальные данные и генерирует синтетические.

Для работы dag следует указать в variables `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACESS_KEY`, `ENDPOINT_URL`, `bucket_name`. Так же следует рядом с папкой `dags` создать `tmp` и положить туда оригинальные данные под именем `origin.csv`, из которых будет генерироваться синтетичесикие. 

### everyday_prediction.py
Этот даг на ежедноевной основе проверят наличие новых данных на s3 за последние сутки. Как только они появляются, он делает и сохраняет предсказания с помощью модели, имя которой указано в `REGISTRY_MODEL_NAME` (из variables Airflow). У модели берётся та версия, которая в стадии production. Для проверки можно использовать `AirflowExampleModel`.

### weekly_model.py
Даг, который еженедельно проверяет есть ли данные за последние сутки (на момент проверки). Как только они появляются и делаться на `val` и `train`, он создаёт новую модель, согласно переменной пути `model_path` из airflow (пример: `model_path=sklearn.linear_model.LogisticRegression`). В качестве конфигурации для этой модели будет использована конфигурация по умолчанию, если в `data/configs` нет соответсвующего `.yml` файла (пример для ранее указанной модели: `sklearn_linear_model_LogisticRegression.yml`). При использовании параметров по умолчанию файл конфигурации будет создан автоматически. 

На созданной модели происходит обучение и замеряются метрики. Все полученные метрики и модель сохраняются на `mlflow`. Для работы необходимы переменные, для работы с s3 (см. описание `new_data_imitation.py`), а так же переменная `MLFLOW_URI`.

```
Перечисленные выше два dags используют сенсор для отслеживания состояния данных. Чтоб он корректно работал нужно настроить connection в airflow. В connection id указать s3_airflow, type: Amazon S3, в extras в формате json перечислить {'aws_access_key_id': 'myid', 'aws_secret_access_key': 'mykey', 'host': 'ENDPOINT_URL'}
```

### send_mail.py
Все даги имеют возможность уведомлять при падении. Для этого важно чтоб работал текущий даг, который используется для проверки работоспособности рассылки с помощью гугл почты. Базовые параметры для работы сервиса передаются при запуске docker-compose. Следует изменить `AIRFLOW__SMTP__SMTP_MAIL_FROM` параметр на ту почту, с которой хочется отправлять запросы.

Так же для корректной работы следует предоставить `airflow` данные для входа в аккаунт гугл. Для этого надо разрешить почте использовать IMAP, а так же создать пароль для входа стороннего приложения (https://myaccount.google.com/apppasswords). После в airflow следует настроить connection. Тип - email. Пароль - из паролей для приложений, логин - почта. Connection id - `smtp_default`.


## Самопроверка

Для проверки дз могу предоставить доступ к s3, mlflow. В целом данные для входа не поменялись с последней дз.

0. Поднимите airflow локально, используя docker compose (можно использовать из примера https://github.com/made-ml-in-prod-2021/airflow-examples/)

1. Реализуйте dag, который генерирует данные для обучения модели (+ 5 баллов) 
  - записывайте данные в /data/raw/{{ ds }}/data.csv и /data/raw/{{ ds }}/target.csv (я пишу сразу в s3 таком же формате)


2. Реализуйте dag, который обучает модель еженедельно, используя данные за текущий день. В вашем пайплайне должно быть как минимум 4 стадии, но дайте волю своей фантазии =) (+ 10 баллов)

- провека данных на s3
- скачивание и распределение на train-test
- обучение модели на train сохранение модели в mlflow
- валидация модели на val, метрики в mlflow


3. Реализуйте dag, который использует модель ежедневно (+ 5 баллов)
- ждёт данные на s3
- скачивает и готовит к предсказанию
- предсказывает и сохраняет



4. все даги реализованы только с помощью DockerOperator. Есть общий докер для ml. Для каждой задачи докер наследуется и в него устанавливаются дополнительные библиотеки (sdv для генерации, mlflow для предсказания на моделях и т.д.). Для предсказания на новой и старой моделях используется один и тот же образ. Отличается только комманда на старте (+ 10 баллов)

5. Традиционно, самооценка ( + 1 балл)

Дополнительная часть:

6. Реализуйте сенсоры на то, что данные готовы для дагов тренировки и обучения (+3 балла)
7. Протестируйте ваши даги - это мне было уже лень делать.
8. В docker compose так же настройте поднятие mlflow и запишите туда параметры обучения, метрики и артефакт (модель) (+5 доп баллов)
Тут я не уверен зачем `docker compose` с mlflow полднимать. Надеюсь то, что я использовал mlflow поднятый ещё на первой домашке это ок.

9. API Mlflow Model Registry (+5 доп баллов)
10. Настроил alert в случае падения дага через gmail (+3 доп балла)
---
ДАЛЕЕ HW2
---
---


# Online inference

## Работа сервиса
Приложение имеет 2 режима работы. 

Тестовый режим запускается, если передана команда `--testmode`. В тестовом режиме добавляется новый `post` запрос по пути `/predict/one`, который облегчает ручное тестированиe через `Swagger UI`. Рекомандовано использовать при проверке ДЗ

Остальные `POST` запросы на предсказание:
- `/predict/json` приниает в качестве аргумента словарь с правильными названиями полей
- `/predict/many/json` принимает в качестве аргумента список словарей (json) из прошлого запроса.
- `predict/many/matrix` принимает в качестве аргумента словарь (json) в формате `{"data_mat": YOUR_MATRIX}`, где `YOUR_MATRIX` - список списков с элементами в правильном порядке. 

Все запросы валидируются.

## Scripts
Скрипт запускается из папки со скриптом. Делает `POST` запрос в `/predict/many/matrix`. Для корректной работы важно, чтоб файл `--input` был формата `csv`, без заголовков и таргета. Примет файла лежит рядом со скриптом. Запуск примера (если сервис запущен на 1234 порту)

`python req_scripts.py --input ./data.csv --port 1234`

HELP:

```
usage: req_scripts.py [-h] [--host HOST] [--port PORT] --input INPUT [--output OUTPUT]

optional arguments:
  -h, --help       show this help message and exit
  --host HOST      host address
  --port PORT      port
  --input INPUT    path to input data in csv format
  --output OUTPUT  path to save file; default print to stdout
```

## Docker 

[Docker Image](https://hub.docker.com/r/theolisin/made)

Pull: `docker pull theolisin/made:mlops-latest`

Run: `docker run -p 1234:80 --env-file PATH_TO_ENV theolisin/made:mlops-latest`

*Выбрал внешний порт 1234, потому что 80 и 8080 уже заняты*

Для корректной работы следует создать .env файл и указать при запуске путь до него `PATH_TO_ENV`. В env должны быть определены
- `MLFLOW_URI` - адрес mlflow из прошлого дз.
- `MODEL_NAME=FinLogReg` - параметр из mlflow model registry
- `MODEL_STAGE=Production` - параметр из mlflow model registry
- `MODEL_VERSION=3` - параметр из mlflow model registry
- `TEST_MODE=--testmode` необязательная переменная, но при проверке через Swagger UI её лучше задать

### Оптимизация размера
Собственно в статье много интересного используется, но Dockerfile у меня совсем маленький по количеству строк, потому всего 2 оптимизации я применил (без них не пробовал, так что не знаю насколько вообще это помогло)

1. Использовал python-slim вместо полноценного
2. Использование .dockerignore чтоб проигнорировать данные, cache и проч.
3. Использовал разбиение requirements в setup.py на те зависимости, что нужны для работы, те что нужны для разработки и тестирования. При установке используются только первая группа.

## Самопроверка HW2

1. Обернул inference модели в rest сервис на FastAPI, есть endpoint /predict (+3 балла)

2. Написал endpoint /health, который должен возращать 200, если ваша модель готова к работе (+1 балл)

3. Написаны pytest (+3 балла)

4. Скрипт делающий запросы к сервису (+2 балла)

5. Dockerfile и все все все (+ 4 балла)

6. https://hub.docker.com/r/theolisin/made образ (+2 балла)

7. README.md про Dockerfile, скрипт проверен (+1 балл)

8. Если вы читаете это, то самопроверка выполнена (+1 балл)

Дополнительная часть:

9. Модель в model registry (+2 доп балла)
10. Оптимизация - ну какая-то есть. В README.md описано что оптимизировано. (+ 1 балл)

11. Validation через Pydantic. И даже 2 конструктора для данных). Ошибка не 400, a 422. Зато валидируется сразу весь входной массив данных и в ошиюбке перечислены все места, где не прошла валидация, а не только самое первое место с ошибкой (+ 2 балла)

---
ДАЛЕЕ HW1
---
---

# Установка пакета

Для работы с проектом как с программой после скачивания репозитория выполнить из корня (желательно в окружении):
```
pip install .
```

Для изменения проекта стоит установить (синтаксис может быть немного другой, если использовать zsh, а не bash)

```
pip install -e .[dev,tests]
```

# .env и DVC
Для корректной работы следует создать `.env` файл и установить следующие переменные среды (за доступом при приверке ДЗ обращаться к владельцу репозитория):
- AWS_ACCESS_KEY_ID
- AWS_SECRET_ACESS_KEY
- ENDPOINT_URL
- MLFLOW_URI

Первые три переменных необязательны, если настроен DVC (см. ниже).

Так же следует создать `.dvc/config.local` и настроить переменные в файле аналогично `.dvc/config` (за доступом при приверке ДЗ обращаться к владельцу репозитория).


# Classification

Вызвать обучение или предсказания можно находясь в любое месте с активированным окружением (в котором установлен пакет) через команду 
`classification`. 

```
usage: classification [-h] (--train | --predict) [--modelid MODELID | --modelpath MODELPATH] [--outfile OUTFILE] [--input INPUT]
                 [--modelname MODELNAME] [--mlflow | --no-mlflow]

optional arguments:
  -h, --help            show this help message and exit
  --train               run train pipline using config.yml file.
  --predict             make prediction on --input using --modelid or last (from config.yml) saved model; store to --outfile
  --modelid MODELID     id of model from mlflow storage
  --modelpath MODELPATH
                        path to model; specify only one of the two arguments 'id' or 'path'
  --outfile OUTFILE     file path to store prediction in 'my/path/file.csv' format; required argument for prediction
  --input INPUT         path to data file for prediction; required argument for prediction
  --modelname MODELNAME
                        this name will be used for saving model, kwargs config and mlflow; default config.model.model_name
  --mlflow              store model and artifacts into mlflow; if not provided use_mlflow parameter from config will be used
  --no-mlflow           prevent saving experiment to mlflow; if not provided use_mlflow parameter from config will be used
```

## Train
Команда `classification --train [--mlflow | --no-mlflow] [--modelname MODELNAME]`.
Для тренировки используются данные из параметра `data_path` конфигурационного файла.

### Если настроены параметры AWS в .env

Если параметр не задан, будет использован путь до данных, которые скачиваются из S3 `${s3.defaultout} / ${s3.defaultfile}`. Если 
данных нет, они будут скачаны из S3 автоматически.

### Если настроен DVC конфиг

При отсутсвии данных выполнить `dvc pull`.

### Конфигурация модели

Для использования той или иной модели в обучении следует настроить следующие параметры:

- module: название модуля/пакета где лежит есть класс модели (прим.: sklearn)
- submodule: модуль пакета (прим.: ensemble)
- model_name: класс модели (прим.: GradientBoostingClassifier)

Задать конфигурацию модели перед обучением можно добавлением файла конфигурации в `/configs/model_configs`
в формате `*_kwargs.yml`. Имя файла должно начинаться с названия модели, указанного в файле `/configs/config.yml`. Название модели параметр `model.save_as`, если он не задан используется `model.model_name`. Если при обучении файл конфигурации не найден, он будет создан автоматически со стандартной конфигурацией, после чего его можно будет изменить и новое обучение будет использовать изменнный файл.

### Трансформеры

В проекте используются 2 кастомных трансформера:
- CatTransformer: 

    трансформирует категориальные фичи в dummy вектора. Тип фичи (категориальная или нет) определяется автоматически по числу уникальных значений. Граница определяется параметром categorical_features_max_uniqs

- ScalerTransformer: 
    
    делает скейлинг numeric фичей. Тип фичи определяется автоматически по числу уникальных значений и питоновскому типу, граница задатся через numeric_features_min_uniqs. Для нормализации используются стандартные скейлеры из sklearn, задатся через параметр scaler


### mlflow

Если задан URL то модели можно сохранять в mlflow. Стандартные модели `sklearn` сохраняться как модель, нестандартные - как артефакт. При сохранении модели в mlflow путь до артефакта будет записан в конфиг как `model.last_model`.

Если при запуске скрипта будет передн один из аргументов `--mlflow` или `--no-mlflow`, то параметр конфигурации `use_mlfow` будет проигнорирован.

### dvc repro

Если настроен DVC то для получения обученной модели можно выполнить `dvc repro`. Будет обучена модель `last`, с конфигурацией `last_kwargs.yml`.

## Prediction
Команда `classification --predict [--modelid MODELID | --modelpath MODELPATH] (--outfile OUTFILE) (--input INPUT)`.

Если `modelid` или `modelpath` не задан, по умолчанию будет использована последняя загруженная в mlflow модель (путь в mlflow берётся из конфигурации).

# Final

0. Описание в README.md (+ 1 балл)
1. Это и есть оценка. Будет скопировано в PR (+ 1 балл)
2. Ноутбук с EDA есть (+ 1 балл)
3. Написана функция/класс для тренировки модели, вызов оформлен как утилита командной строки, записана в readme инструкцию по запуску (+ 3 балла)
4. Написана функция/класс predict (вызов оформлен как утилита командной строки), которая примет на вход артефакт/ы от обучения, тестовую выборку (без меток) и запишет предикт по заданному пути, инструкция по вызову записана в readme (+ 3 балла)
5. Проект имеет модульную структуру (+ 2 балла)
6. Использованы логгеры (+ 2 балла)
7. Написаны тесты на отдельные модули и на прогон обучения и predict (+ 3 балла)
8. Для тестов генерируются синтетические данные, приближенные к реальным (+ 2 балла)
9. Обучение модели конфигурируется с помощью конфигов в json или yaml, добавил две конфигурации для разных классов моделей (+ 3 балла)
10. Используются датаклассы для сущностей из конфига, а не голые dict (+ 2 балла)
11. Напишите кастомный трансформер (есть целых два) и протестируйте его (+ 3 балла) 
12. В проекте зафиксированы все зависимости (в setup.py) (+ 1 балл) 
13. Настроен CI для прогона тестов, линтера на основе github actions (+ 3 балла).
14. Используйте hydra для конфигурирования - не вышло настроить гидру для проекта, в котором при запуске происходит парсинг аргументов, т.е. не получится использовать @hydra.main(). Было бы интересно узнать как действовать в такм случае (например через compose и initialize) - + 0 баллов
15. разверните локально mlflow или на какой-нибудь виртуалке (+ 1 балл)
16. залогируйте метрики (+ 1 балл)
17. воспользуйтесь Model Registry для регистрации модели. Скриншота не будет, просто дам ссылку на mlflow с моделями (+ 1 балл)
18. выделите в своем проекте несколько entrypoints в виде консольных утилит (+ 1 балл).
19. добавьте датасет под контроль версий (+ 1 балл)
20. сделайте dvc пайплайн для изготовления модели(+ 1 балл)
